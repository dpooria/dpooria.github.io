<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>dpoor|Research</title>
    <link rel="stylesheet" href="css/main.css">
    <link rel="icon" type="image/png" href="favicon.png" />
</head>

<body>
    <div class="navbar-top">
        <div class="container">
            <a class="dpoorlogo" href="#">dp<span>oo</span>r</a>
            <img id="mobile-cta" class="mobile-menu" src="images/hamburger.svg" alt="Open Nav">
            <nav id="pnav">
                <img id="mobile-exit" class="mobile-menu-exit" src="images/exit.svg" alt="exit">
                <ul class="primary-nav">
                    <li><a href="index.html">Home</a></li>
                    <li class="current"><a href="research.html">Research</a></li>
                    <li><a href="projects.html">Projects</a></li>

                </ul>
                <ul class="secondary-nav">
                    <li><a href="mailto:dpooria75@gmail.com">Contact</a></li>
                    <li><a href="dpoor.html">About Me</a></li>
                </ul>
            </nav>
        </div>
    </div>


    </section>
    <section class="table-hero">
        <h1 class="title">Reaserch Works</h1>
        <div class="container">
            <ul class="selected-list">
                <li>
                    <div class="dropdown">
                        <button onclick="dropdown_func('confusion')"
                            class="dropbtn confusion-dropbtn">Confusion on ultracold
                            atoms</button>
                        <div id="confusion" class="dropdown-content">
                            <button class="show dropbtn2" onclick="dropdown_func('double-phase-transition')">Double
                                Confusion</button>
                            <div id="double-phase-transition" class="dropdown-content">
                                <div class="explain">
                                    <h2>
                                        Implementation of the confusion scheme on snapshots of ultra-cold quantum gas
                                        experiment to detect the topological phase transition of the Haldane model
                                    </h2>
                                    <p>
                                        To implement the confusion scheme on this dataset a few modification has been
                                        made to the original method, first as the data is high dimensional I've used a
                                        deeper network with convolutional layers as opposed to the shallow fully
                                        connected network suggested by the paper.
                                        Secondly the Haldane model in the phase &phi;=-&pi;/2 has two critical
                                        frequencies, theoretically the Haldane model is topologically trivial in &omega;
                                        <6.1 and &omega;>
                                            6.8 and topological, C=-1, in between.
                                            So we have a double phase transition on our hand and the universal <bf>W
                                            </bf> shape here has two peaks in the middle showing two critical points.
                                    </p>
                                </div>

                                <script
                                    src="https://gist.github.com/dpooria/db44ff7f30556cfdbbfd3522c78fafe6.js"></script>
                                <script
                                    src="https://gist.github.com/dpooria/1832dd461f13d44ec5ea8744bdbcf9d7.js"></script>
                            </div>

                            <button class="show dropbtn2" onclick="dropdown_func('dcn')">DCN</button>
                            <div id="dcn" class="dropdown-content">
                                <div class="explain">
                                    <h2>Discriminative Cooperative networks on snapshots of ultra-cold atoms
                                    </h2>
                                    <p>
                                        This is a try to apply the <a
                                            href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.176401">DCN
                                            method</a> to detect topological phase transition of the Haldane
                                        method from
                                        snapshots of the ultra-cold atoms experiment. The dataset is the same as the one
                                        used
                                        in
                                        the paper <a href="https://iopscience.iop.org/article/10.1088/2632-2153/abffe7">
                                            Unsupervised machine learning of topological phase transitions from
                                            experimental
                                            data </a> and you can access it from <a
                                            href="https://zenodo.org/record/4459311">
                                            here </a>.</p>
                                    <p>
                                        I suspect the problem is either
                                    </p>
                                    <ol>
                                        <li>
                                            Data being high dimensional and DCN method has been implemented only on
                                            low
                                            dimensional (80d) array of entanglement spectrum and one key difference
                                            from
                                            confusion method is the interpolation of data in continuos parameter
                                            space
                                            and
                                            in their implementation they have used a linear interpolation that
                                            simply
                                            doesn't work on our images. I tried to overcome this issue by
                                            implementing a
                                            generative model with variational autoencoder with question neuron as
                                            suggested
                                            in <a
                                                href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.124.010508">this
                                                paper</a> and has been utilized to remove micromotions from this
                                            dataset. In
                                            my implementation I added two other question neurons for frequency and
                                            phase
                                            of
                                            the images so you have a way to control the generated image parameters
                                            but
                                            this
                                            didn't work either and there is no guarantee that the generated snapshots
                                            contain
                                            meaningful physical properties.
                                        </li>
                                        <li>
                                            One issue that hasn't been addressed in the DCN method is that if the
                                            guesser
                                            model is trying to minimize the loss function of learner model from the
                                            <a href="https://www.nature.com/articles/nphys4037"> confusion
                                                method</a>
                                            the
                                            global minima of the loss function is where all labels are the same (the
                                            boundary peaks of the universal <b>W</b> shape) and not the critical
                                            point.
                                            For
                                            overcoming this issue I tried to make the guesser model to propose the
                                            right
                                            critical point by rewarding the higher variant labels but it just made
                                            the
                                            model to not learn anything.
                                        </li>
                                    </ol>
                                </div>
                                <script
                                    src="https://gist.github.com/dpooria/0e6de7747a4a0c973dc333868f282c9e.js"></script>
                                <script
                                    src="https://gist.github.com/dpooria/a1720fd4a8628d0b655a1a96f3785aec.js"></script>
                            </div>
                            <button class="show dropbtn2" onclick="dropdown_func('cvae')">CVAE</button>
                            <div id="cvae" class="dropdown-content">
                                <div class="explain">
                                    <h2>Generating Snapshots of Ultracold Quantum Gas Experiment with Variational
                                        Autoencoders
                                    </h2>

                                    <p>
                                        This is a try to generate new samples from <a
                                            href="https://iopscience.iop.org/article/10.1088/2632-2153/abffe7">this
                                            dataset</a> by adding two more
                                        question neurons to the original model that has been used in order to
                                        remove the micromotions phase. The idea is that if one can change the
                                        micromotion of
                                        sampled images with experiment why can't you just generate new images in the
                                        desired parameters (with specific frequency and phase in our case).
                                        The problem is that I couldn't find a clear way to evaluate the generated
                                        images,
                                        and
                                        it raises the question wether the generated snapshots preserve meaningful
                                        physical properties.
                                        If you have any suggestion regarding this I would be happy to discuss this.
                                    </p>
                                </div>
                                <script
                                    src="https://gist.github.com/dpooria/1de1c6f3552c2fe0e51c2e381d6927ee.js"></script>
                            </div>

                        </div>
                    </div>
                </li>
                <li>
                    <div class="dropdown">
                        <button onclick="dropdown_func('rl')" class="dropbtn rl-dropbtn"
                            id="rl-btn">Reinforcement learning
                            quantum
                            phase
                            transitions</button>
                        <div id="rl" class="dropdown-content">
                            <button class="show dropbtn2" onclick="dropdown_func('rl-qlearning')">QLearning</button>
                            <div id="rl-qlearning" class="dropdown-content">
                                <div class="explain">
                                    <h2>Reformulating the detection of quantum phase transition as a deep reinforcement
                                        learning problem
                                    </h2>

                                    <p>
                                        I defined the environment as a set of nodes living in the parameter space,
                                        presenting the phase diagram of the many-body physical system under study. The
                                        agent can take action to change the coordinates of these nodes to obtain the
                                        physical system's phase diagram. The rewarding system for this environment is
                                        defined as the performance of a shallow neural network trained with the
                                        suggested phase diagram by the agent as an indicator of how well it is doing
                                        (confusion scheme).
                                        Here I used the QLearning method which requires a discrete action space and by
                                        using SAC we can use a continous action space.
                                    </p>
                                </div>
                                <script
                                    src="https://gist.github.com/dpooria/542b5e45a62fa658a94180818915fd0c.js"></script>
                                <script
                                    src="https://gist.github.com/dpooria/9a7a6da3e28b257f2eec22bd2d1c9495.js"></script>

                            </div>
                            <button class="show dropbtn2" onclick="dropdown_func('rl-sac')">SAC</button>
                            <div id="rl-sac" class="dropdown-content">
                                <div class="explain">
                                    <h2>Soft Actor-Critic Learning Physics
                                    </h2>

                                    <p>
                                        Coming soon...
                                    </p>
                                </div>
                            </div>

                        </div>
                    </div>
                </li>
            </ul>
        </div>
    </section>

    <div class="navigate">
        <div class="container">
            <nav class="navbar">
                <div class="primary">
                    <a href="index.html">Home</a>
                    <a href="research.html">Research</a>
                    <a href="projects.html">Projects</a>
                    <a href="dpoor.html">dpoor</a>
                    <a href="mailto:dpooria75@gmail.com">Contact</a>

                </div>
                <div class="secondary">
                    <a target="_blank" href="https://github.com/dpooria">
                        <img src="images/iconmonstr-github-1.svg" alt="github">
                    </a>
                    <a target="_blank" href="https://twitter.com/pooriadabaghi">
                        <img src="images/iconmonstr-twitter-1.svg" alt="twitter">
                    </a>
                    <a target="_blank" href="https://www.linkedin.com/in/pooria-dabbaghi-64b808167/">
                        <img src="images/iconmonstr-linkedin-3.svg" alt="linkedin">
                    </a>

                    <a target="_blank" href="https://www.researchgate.net/profile/Pooria-Dabbaghi">
                        <img class="researchgate" src="images/researchgate.svg" alt="linkedin">
                    </a>
                    <a target="_blank" href="#">
                        <img src="images/logo.png" alt="dpoor">
                    </a>
                </div>
            </nav>
        </div>
    </div>
    <script>
        const mobileBtn = document.getElementById('mobile-cta')
        nav = document.getElementById('pnav')
        mobileBtnExit = document.getElementById('mobile-exit')
        mobileBtn.addEventListener('click', () => {
            nav.classList.add('menu-btn')
            mobileBtn.classList.add('hide')
        })


        mobileBtnExit.addEventListener('click', () => {
            nav.classList.remove('menu-btn')
            mobileBtn.classList.remove('hide')

        })

        function dropdown_func(id) {
            document.getElementById(id).classList.toggle("show");
        }
        // Close the dropdown if the user clicks outside of it
        // window.onclick = function (e) {
        //     if (!e.target.matches('.dropbtn') && !e.target.matches('.dropbtn2')) {
        //         var rl_dropdown = document.getElementById("rl-dropdown");
        //         if (rl_dropdown.classList.contains('show')) {
        //             rl_dropdown.classList.remove('show');
        //         }
        //         var confusion_dropdown = document.getElementById("confusion-dropdown");
        //         if (confusion_dropdown.classList.contains('show')) {
        //             confusion_dropdown.classList.remove('show');
        //         }
        //     }
        // }
        const queryString = window.location.search;
        console.log(queryString);
        const urlParams = new URLSearchParams(queryString);
        if (urlParams.has('section')) {
            sect = urlParams.get('section')
            // console.log(sect)
            // document.getElementById(sect).classList.toggle("show");
            dropdown_func(sect)
            if (urlParams.has('subsection')) {
                subsect = urlParams.get('subsection')
                // console.log(subsect)
                // document.getElementById(sect).classList.toggle("show");
                dropdown_func(subsect)
            }
        }
    </script>
</body>

</html>